{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c43d2-47bf-40d0-b674-952fc04ec004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doubt import Boot\n",
    "from doubt.datasets import (Airfoil, Blog, Concrete, CPU, \n",
    "                            FacebookComments, FishBioconcentration,\n",
    "                            FishToxicity, ForestFire, NewTaipeiHousing,\n",
    "                            PowerPlant, Protein, Servo,\n",
    "                            SpaceShuttle)\n",
    "from mapie.regression import MapieRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886688c-41ac-46a8-8e30-20e22756b5ec",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd591da-511f-4fc0-8aee-99ec6218b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nasa(model, X_tr, X_te, y_tr, y_te, uncertainty=0.05):\n",
    "    n_boots = int(np.sqrt(len(X_tr)))\n",
    "    \n",
    "    # Calculate training residuals\n",
    "    model.fit(X_tr, y_tr)\n",
    "    tr_preds = model.predict(X_tr)\n",
    "    te_preds = model.predict(X_te)\n",
    "    tr_residuals = y_tr - tr_preds\n",
    "    \n",
    "    n_train = X_tr.shape[0]\n",
    "    n_test = X_te.shape[0]\n",
    "\n",
    "    # Initialise random number generator\n",
    "    rng = np.random.default_rng(4242)\n",
    "\n",
    "    # Compute the model variances\n",
    "    bootstrap_preds = np.empty((n_boots, n_test))\n",
    "    for boot_idx in range(n_boots):\n",
    "        train_idxs = rng.choice(range(n_train), size=n_train, replace=True)\n",
    "        X_btr = X_tr[train_idxs, :]\n",
    "        y_btr = y_tr[train_idxs]\n",
    "\n",
    "        model.fit(X_btr, y_btr)\n",
    "        \n",
    "        bootstrap_pred = model.predict(X_te)\n",
    "        bootstrap_preds[boot_idx] = bootstrap_pred\n",
    "\n",
    "    # Centre the bootstrapped predictions across the bootstrap dimension\n",
    "    bootstrap_preds = np.mean(bootstrap_preds, axis=0) - bootstrap_preds\n",
    "\n",
    "    # Add up the bootstrap predictions and the hybrid train/val residuals\n",
    "    C = np.array([m + o for m in bootstrap_preds for o in tr_residuals])\n",
    "\n",
    "    # Calculate the intervals\n",
    "    intervals = np.expand_dims(te_preds, -1) + np.transpose(np.quantile(C, q=[uncertainty/2, 1-uncertainty/2], axis=0))\n",
    "    \n",
    "    coverage = np.mean((y_te > intervals[:, 0]) & (y_te < intervals[:, 1]))\n",
    "    mean_width = np.mean(intervals[:, 1] - intervals[:, 0])\n",
    "    return coverage, mean_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bd112-6ae2-42cd-b38c-27d94cd42195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_doubt(model, X_tr, X_te, y_tr, y_te, uncertainty=0.05):\n",
    "    n_boots = int(np.sqrt(len(X_tr)))\n",
    "    \n",
    "    bmodel = Boot(model, random_seed=4242)\n",
    "    bmodel.fit(X_tr, y_tr, n_boots=n_boots)\n",
    "    preds, intervals = bmodel.predict(X_te, uncertainty=uncertainty, n_boots=n_boots)\n",
    "    \n",
    "    coverage = np.mean((y_te > intervals[:, 0]) & (y_te < intervals[:, 1]))\n",
    "    mean_width = np.mean(intervals[:, 1] - intervals[:, 0])\n",
    "    return coverage, mean_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c6541-d71f-4ff8-b57a-1b6422adf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mapie(model, X_tr, X_te, y_tr, y_te, uncertainty=0.05):\n",
    "    bmodel = MapieRegressor(model)\n",
    "    bmodel.fit(X_tr, y_tr)\n",
    "    preds, intervals = bmodel.predict(X_te, alpha=uncertainty)\n",
    "    \n",
    "    coverage = np.mean((y_te > intervals[:, 0, 0]) & (y_te < intervals[:, 1, 0]))\n",
    "    mean_width = np.mean(intervals[:, 1] - intervals[:, 0])\n",
    "    return coverage, mean_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f75e0-2c54-4d48-99b5-d4909525779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Add Doubt datasets\n",
    "dataset_classes = [\n",
    "    Airfoil,\n",
    "    Concrete,\n",
    "    FishToxicity,\n",
    "    ForestFire,\n",
    "    NewTaipeiHousing,\n",
    "    PowerPlant,\n",
    "    Protein,\n",
    "    Servo,\n",
    "]\n",
    "\n",
    "for dataset_class in dataset_classes:\n",
    "    dataset = dataset_class()\n",
    "    dataset._data = dataset._data.sample(n=min(len(dataset), 10000), random_state=4242)\n",
    "    X_tr, X_te, y_tr, y_te = dataset.split(test_size=0.1, random_seed=4242)\n",
    "    X_tr = scaler.fit_transform(X_tr)\n",
    "    X_te = scaler.transform(X_te)\n",
    "    datasets.append((dataset_class.__name__, X_tr, X_te, y_tr, y_te))\n",
    "    \n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0919d-56cc-420f-9612-7ff5ab51fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, X_tr, X_te, y_tr, y_te in datasets:\n",
    "    print(f'{name}: {len(X_tr) + len(X_te):,} samples, {X_tr.shape[-1]:,} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d03b72-cc4f-4ee3-8d4e-4df8764f2f40",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340bc31-1deb-4af5-8a11-f42db66e85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982358c1-6398-474f-a0a6-5ad9c2b11604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = defaultdict(list)\n",
    "for dataset in tqdm(datasets):\n",
    "    for uncertainty in tqdm(np.arange(0.01, 0.51, 0.01), leave=False):\n",
    "        nasa_coverage, nasa_mean_width = evaluate_nasa(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        doubt_coverage, doubt_mean_width = evaluate_doubt(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        mapie_coverage, mapie_mean_width = evaluate_mapie(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        data_dict['dataset'].append(dataset[0])\n",
    "        data_dict['uncertainty'].append(uncertainty)\n",
    "        data_dict['nasa_coverage_error'].append(100 * (1 - uncertainty - nasa_coverage))\n",
    "        data_dict['doubt_coverage_error'].append(100 * (1 - uncertainty - doubt_coverage))\n",
    "        data_dict['mapie_coverage_error'].append(100 * (1 - uncertainty - mapie_coverage))\n",
    "        data_dict['nasa_mean_width'].append(nasa_mean_width)\n",
    "        data_dict['doubt_mean_width'].append(doubt_mean_width)\n",
    "        data_dict['mapie_mean_width'].append(mapie_mean_width)\n",
    "    \n",
    "linreg_df = pd.DataFrame(data_dict).set_index(['dataset', 'uncertainty'])\n",
    "linreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220656f8-ac9f-4d05-97e3-8eaeb965ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(linreg_df.abs()\n",
    "          .describe()\n",
    "          .loc[['mean', 'std']]\n",
    "          .T\n",
    "          .sort_values(by='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad241c-df99-4731-bef6-94cb7126737c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for method in ['mapie', 'doubt', 'nasa']:\n",
    "    print(method.title())\n",
    "    for x in linreg_df[f'{method}_coverage_error'].abs():\n",
    "        print(f'{x:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a28d3-4b59-404c-9591-c7718ddafd85",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddfbd4-8edd-42bc-b3de-529ad18196ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b23a2-4de3-457c-b8cd-82e3895e8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = defaultdict(list)\n",
    "for dataset in tqdm(datasets):\n",
    "    for uncertainty in tqdm([0.01, 0.05, 0.1], leave=False):\n",
    "        nasa_coverage, nasa_mean_width = evaluate_nasa(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        doubt_coverage, doubt_mean_width = evaluate_doubt(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        mapie_coverage, mapie_mean_width = evaluate_mapie(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        data_dict['dataset'].append(dataset[0])\n",
    "        data_dict['uncertainty'].append(uncertainty)\n",
    "        data_dict['nasa_coverage_error'].append(100 * (1 - uncertainty - nasa_coverage))\n",
    "        data_dict['doubt_coverage_error'].append(100 * (1 - uncertainty - doubt_coverage))\n",
    "        data_dict['mapie_coverage_error'].append(100 * (1 - uncertainty - mapie_coverage))\n",
    "        data_dict['nasa_mean_width'].append(nasa_mean_width)\n",
    "        data_dict['doubt_mean_width'].append(doubt_mean_width)\n",
    "        data_dict['mapie_mean_width'].append(mapie_mean_width)\n",
    "    \n",
    "tree_df = pd.DataFrame(data_dict).set_index(['dataset', 'uncertainty'])\n",
    "tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68682880-fc6e-4167-a011-355800c1dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tree_df.abs()\n",
    "        .describe()\n",
    "        .loc[['mean', 'std']]\n",
    "        .T\n",
    "        .sort_values(by='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a26ca-f578-478b-b5fc-5f99d424c79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for method in ['mapie', 'doubt', 'nasa']:\n",
    "    print(method.title())\n",
    "    for x in tree_df[f'{method}_coverage_error'].abs():\n",
    "        print(f'{x:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d6287-b8bf-4301-ae91-dc23705121d1",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254a838-9791-4612-ad77-589f531fc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3be9f8-86b2-41fa-8f7a-1000eb15aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = defaultdict(list)\n",
    "for dataset in tqdm(datasets):\n",
    "    for uncertainty in tqdm([0.01, 0.05, 0.1], leave=False):\n",
    "        nasa_coverage, nasa_mean_width = evaluate_nasa(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        doubt_coverage, doubt_mean_width = evaluate_doubt(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        mapie_coverage, mapie_mean_width = evaluate_mapie(model, *dataset[1:], uncertainty=uncertainty)\n",
    "        data_dict['dataset'].append(dataset[0])\n",
    "        data_dict['uncertainty'].append(uncertainty)\n",
    "        data_dict['nasa_coverage_error'].append(100 * (1 - uncertainty - nasa_coverage))\n",
    "        data_dict['doubt_coverage_error'].append(100 * (1 - uncertainty - doubt_coverage))\n",
    "        data_dict['mapie_coverage_error'].append(100 * (1 - uncertainty - mapie_coverage))\n",
    "        data_dict['nasa_mean_width'].append(nasa_mean_width)\n",
    "        data_dict['doubt_mean_width'].append(doubt_mean_width)\n",
    "        data_dict['mapie_mean_width'].append(mapie_mean_width)\n",
    "    \n",
    "forest_df = pd.DataFrame(data_dict).set_index(['dataset', 'uncertainty'])\n",
    "forest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38e1ac-470c-45cc-af43-7c598528d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(forest_df.abs()\n",
    "        .describe()\n",
    "        .loc[['mean', 'std']]\n",
    "        .T\n",
    "        .sort_values(by='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae9d1c-b9ed-424f-805c-d412519920a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for method in ['mapie', 'doubt', 'nasa']:\n",
    "    print(method.title())\n",
    "    for x in forest_df[f'{method}_coverage_error'].abs():\n",
    "        print(f'{x:.4f}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
